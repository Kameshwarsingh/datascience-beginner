installed.packages("dslabs")
library(dslabs)
install.packages("dslabs")
#Q1
x <- c(2, 43, 27, 96, 18)
sort(x)
order(x)
rank(x)
#Q2
min(x)
which.min(x)
max(x)
which.max(x)
#Q3
name <- c("Mandi", "Amy", "Nicole", "Olivia")
distance <- c(0.8, 3.1, 2.8, 4.0)
time <- c(10, 30, 40, 50)
names(distance) <- name
distance
names(time) <- name
time
v <- cbind(time,distance)
str(v)
df<- data.frame(v)
str(df)
print(df)
time_in_hr <- c(df$time / 60)
time_in_hr
df$time_in_hr = time_in_hr
df
speed_miles_pr_hr <- c(df$distance/df$time_in_hr)
speed_miles_pr_hr
df$speed_miles_pr_hr = speed_miles_pr_hr
df
library(dslabs)
data(heights)
options(digits = 3)
str(heights)
avg(heights$height)
ind <- ( heights$height > avg(heights$height))
ind
sum(ind)
levels(heights$sex)
ind_female <- ( heights$sex=="Female")
ind_q2 <- ind & ind_female
sum(ind_q2)
mean(ind_female)
min(heights$height)
?match
match(min(heights$height),heights$height)
heights$sex[1032]
ind_q2 <- ind & ind_female
ind <- ( heights$height > avg(heights$height))
avg(heights$height)
library(dslabs)
data(heights)
options(digits = 3)
str(heights)
avg(heights$height)
average(heights$height)
mean(heights$height)
ind <- ( heights$height > mean(heights$height))
ind
sum(ind)
levels(heights$sex)
ind_female <- ( heights$sex=="Female")
ind_q2 <- ind & ind_female
sum(ind_q2)
mean(ind_female)
min(heights$height)
?match
match(min(heights$height),heights$height)
heights$sex[1032]
library(tidyverse)
library(dslabs)
data("murders")
class(murders)
glimpse(murders)
structure(murders)
str(murders)
names(murders)
#factors
str(murders)
levels(murders$region)
levels(factor(murders$state))
murders %>%
ggplot(aes(population, total, label=abb, color=region))+
geom_label()
?ggplot
#https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf
ggplot(data=murders, mapping=aes(x=population, y=total, label=abb, color=region))+
geom_label()
ls()
log(exp(1))
# We may create vectors of class numeric or character with the concatenate function
codes <- c(380, 124, 818)
country <- c("italy", "canada", "egypt")
# We can also name the elements of a numeric vector
# Note that the two lines of code below have the same result
codes <- c(italy = 380, canada = 124, egypt = 818)
codes <- c("italy" = 380, "canada" = 124, "egypt" = 818)
# We can also name the elements of a numeric vector using the names() function
codes <- c(380, 124, 818)
country <- c("italy","canada","egypt")
names(codes) <- country
codes
# Using square brackets is useful for subsetting to access specific elements of a vector
codes[2]
codes[c(1,3)]
codes[1:2]
# If the entries of a vector are named, they may be accessed by referring to their name
codes["canada"]
codes[c("egypt","italy")]
seq(1,10)
#Sorting
library(dslabs)
data(murders)
sort(murders$total)
x <- c(31, 4, 15, 92, 65)
x
sort(x)    # puts elements in order
index <- order(x)    # returns index that will put x in order
x[index]    # rearranging by this index puts elements in order
order(x)
murders$state[1:10]
murders$abb[1:10]
index <- order(murders$total)
murders$abb[index]    # order abbreviations by total murders
max(murders$total)    # highest number of total murders
i_max <- which.max(murders$total)    # index with highest number of murders
murders$state[i_max]    # state name with highest number of total murders
x <- c(31, 4, 15, 92, 65)
x
rank(x)    # returns ranks (smallest to largest)
#vector arthimatic
which.max(murders$population)
murders$state[which.max(murders$population)]
max(murders$population)
# The name of the state with the maximum population is found by doing the following
murders$state[which.max(murders$population)]
# how to obtain the murder rate
str(murders)
murders$total    # highest number of total murders
murder_rate <- murders$total / murders$population * 100000
murder_rate
# ordering the states by murder rate, in decreasing order
murders$state[order(murder_rate, decreasing=TRUE)]
# defining murder rate as before
murder_rate <- murders$total / murders$population * 100000
# creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71
index <- murder_rate <= 0.71
index
# determining which states have murder rates less than or equal to 0.71
murders$state[index]
# calculating how many states have a murder rate less than or equal to 0.71
sum(index)
# creating the two logical vectors representing our conditions
west <- murders$region == "West"
west
safe <- murder_rate <= 1
safe
# defining an index and identifying states with both conditions true
index <- safe & west
murders$state[index]
x <- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)
which(x)    # returns indices that are TRUE
# to determine the murder rate in Massachusetts we may do the following
index <- which(murders$state == "Massachusetts")
index
murder_rate[index]
# to obtain the indices and subsequent murder rates of New York, Florida, Texas, we do:
index <- match(c("New York", "Florida", "Texas"), murders$state)
index
murders$state[index]
murder_rate[index]
x <- c("a", "b", "c", "d", "e")
y <- c("a", "d", "f")
y %in% x
# to see if Boston, Dakota, and Washington are states
c("Boston", "Dakota", "Washington") %in% murders$state
# installing and loading the dplyr package
#install.packages("dplyr")
library(dplyr)
# adding a column with mutate
library(dslabs)
data("murders")
murders <- mutate(murders, rate = total / population * 100000)
# subsetting with filter
filter(murders, rate <= 0.71)
# selecting columns with select
new_table <- select(murders, state, region, rate)
murders %>%
select(state, region, rate) %>%
filter(rate <= 0.71)
# creating a data frame with stringAsFactors = FALSE
grades <- data.frame(names = c("John", "Juan", "Jean", "Yao"),
exam_1 = c(95, 80, 90, 85),
exam_2 = c(90, 85, 85, 90),
stringsAsFactors = FALSE)
glimpse(grades)
class(grades)
grades
#####################################################################################
#basic plots
# a simple scatterplot of total murders versus population
x <- murders$population /10^6
y <- murders$total
plot(x, y)
# a histogram of murder rates
hist(murders$rate)
# boxplots of murder rates by region
boxplot(rate~region, data = murders)
#######################################################################################
##Programming Basics
# an example showing the general structure of an if-else statement
a <- 0
if(a!=0){
print(1/a)
} else{
print("No reciprocal for 0.")
}
# an example that tells us which states, if any, have a murder rate less than 0.5
library(dslabs)
data(murders)
murder_rate <- murders$total / murders$population*100000
ind <- which.min(murder_rate)
if(murder_rate[ind] < 0.5){
print(murders$state[ind])
} else{
print("No state has murder rate that low")
}
# changing the condition to < 0.25 changes the result
if(murder_rate[ind] < 0.25){
print(murders$state[ind])
} else{
print("No state has a murder rate that low.")
}
# the ifelse() function works similarly to an if-else conditional
a <- 0
ifelse(a > 0, 1/a, NA)
# the ifelse() function is particularly useful on vectors
a <- c(0,1,2,-4,5)
result <- ifelse(a > 0, 1/a, NA)
# the ifelse() function is also helpful for replacing missing values
data(na_example)
no_nas <- ifelse(is.na(na_example), 0, na_example)
sum(is.na(no_nas))
# the any() and all() functions evaluate logical vectors
z <- c(TRUE, TRUE, FALSE)
any(z)
all(z)
######################################################################################################
# example of defining a function to compute the average of a vector x
avg <- function(x){
s <- sum(x)
n <- length(x)
s/n
}
# we see that the above function and the pre-built R mean() function are identical
x <- 1:100
identical(mean(x), avg(x))
# variables inside a function are not defined in the workspace
s <- 3
avg(1:10)
s
# functions can have multiple arguments as well as default values
avg <- function(x, arithmetic = TRUE){
n <- length(x)
ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))
}
x <- 1:5
x
prod(x)
sum(x)
# creating a function that computes the sum of integers 1 through n
compute_s_n <- function(n){
x <- 1:n
sum(x)
}
# a very simple for-loop
for(i in 1:5){
print(i)
}
# a for-loop for our summation
m <- 25
s_n <- vector(length = m) # create an empty vector
for(n in 1:m){
s_n[n] <- compute_s_n(n)
}
# creating a plot for our summation function
n <- 1:m
plot(n, s_n)
# a table of values comparing our function to the summation formula
head(data.frame(s_n = s_n, formula = n*(n+1)/2))
# overlaying our function with the summation formula
plot(n, s_n)
lines(n, n*(n+1)/2)
####################################################################
####################################################################
# apply()
####################################################################
# apply()
# sapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
####################################################################
# apply()
# sapply()
# tapply(vector, index, function)
# mapply()
#logistic regression
library(caret)
fit_glm <- glm(y~x_1+x_2, data=mnist_27$train, family="binomial")
p_hat_logistic <- predict(fit_glm, mnist_27$test)
y_hat_logistic <- factor(ifelse(p_hat_logistic > 0.5, 7, 2))
confusionMatrix(data = y_hat_logistic, reference = mnist_27$test$y)$overall[1]
#logistic regression
library(caret)
fit_glm <- glm(y~x_1+x_2, data=mnist_27$train, family="binomial")
p_hat_logistic <- predict(fit_glm, mnist_27$test)
y_hat_logistic <- factor(ifelse(p_hat_logistic > 0.5, 7, 2))
confusionMatrix(data = y_hat_logistic, reference = mnist_27$test$y)$overall[1]
#fit knn model
knn_fit <- knn3(y ~ ., data = mnist_27$train)
x <- as.matrix(mnist_27$train[,2:3])
y <- mnist_27$train$y
knn_fit <- knn3(x, y)
knn_fit <- knn3(y ~ ., data = mnist_27$train, k=5)
y_hat_knn <- predict(knn_fit, mnist_27$test, type = "class")
confusionMatrix(data = y_hat_knn, reference = mnist_27$test$y)$overall["Accuracy"]
#Over training vs under training
y_hat_knn <- predict(knn_fit, mnist_27$train, type = "class")
confusionMatrix(data = y_hat_knn, reference = mnist_27$train$y)$overall["Accuracy"]
y_hat_knn <- predict(knn_fit, mnist_27$test, type = "class")
confusionMatrix(data = y_hat_knn, reference = mnist_27$test$y)$overall["Accuracy"]
#fit knn with k=1
knn_fit_1 <- knn3(y ~ ., data = mnist_27$train, k = 1)
y_hat_knn_1 <- predict(knn_fit_1, mnist_27$train, type = "class")
confusionMatrix(data=y_hat_knn_1, reference=mnist_27$train$y)$overall[["Accuracy"]]
#fit knn with k=401
knn_fit_401 <- knn3(y ~ ., data = mnist_27$train, k = 401)
y_hat_knn_401 <- predict(knn_fit_401, mnist_27$test, type = "class")
confusionMatrix(data=y_hat_knn_401, reference=mnist_27$test$y)$overall["Accuracy"]
#pick the k in knn
ks <- seq(3, 251, 2)
library(tidyverse)
accuracy <- map_df(ks, function(k){
fit <- knn3(y ~ ., data = mnist_27$train, k = k)
y_hat <- predict(fit, mnist_27$train, type = "class")
cm_train <- confusionMatrix(data = y_hat, reference = mnist_27$train$y)
train_error <- cm_train$overall["Accuracy"]
y_hat <- predict(fit, mnist_27$test, type = "class")
cm_test <- confusionMatrix(data = y_hat, reference = mnist_27$test$y)
test_error <- cm_test$overall["Accuracy"]
tibble(train = train_error, test = test_error)
})
#pick the k that maximizes accuracy using the estimates built on the test data
ks[which.max(accuracy$test)]
max(accuracy$test)
library(dslabs)
library(dplyr)
library(lubridate)
data(reported_heights)
dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 & between(minute(date_time), 15, 30), "inclass","online")) %>%
select(sex, type)
y <- factor(dat$sex, c("Female", "Male"))
x <- dat$type
names(reported_heights)
names(dat)
glimpse(dat)
dat %>%
group_by(sex) %>%
summarise(count=n())
inclass_by_gender <- dat %>%
filter(type=="inclass") %>%
group_by(sex) %>%
summarise(count=n())
inclass_by_gender
##Female within  type=inclass
print("Ratio of Female-gender in Inclass-type ")
(inclass_by_gender %>% filter(sex=="Female"))$count / sum((inclass_by_gender$count))
##Male within  type=inclass
print("Just to validate ratio summation")
(inclass_by_gender %>% filter(sex=="Male"))$count / sum((inclass_by_gender$count))
online_by_gender <- dat %>%
filter(type=="online") %>%
group_by(sex) %>%
summarise(count=n())
online_by_gender
##Female within  type=online
print("Ratio of Female-gender in online-type ")
(online_by_gender %>% filter(sex=="Female"))$count / sum((online_by_gender$count))
##Male within  type=online
print("Just to validate ratio summation")
(online_by_gender %>% filter(sex=="Male"))$count / sum((online_by_gender$count))
#########################################################################################
library(tidyverse)
library(caret)
library(dslabs)
data(reported_heights)
dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 & between(minute(date_time), 15, 30), "inclass","online")) %>%
select(sex, type)
y <- factor(dat$sex, c("Female", "Male"))
x <- dat$type
glimpse(dat)
glimpse(y)
glimpse(x)
set.seed(2000)
test_index <- createDataPartition(y, times = 1, p = 1.0, list = FALSE)
glimpse(test_index)
y_hat <- sample(c("Male", "Female"), length(dat), replace = TRUE)
glimpse(y_hat)
mean(y_hat == dat$sex)
# examine the accuracy of 10 cutoffs
cutoff <- c("online","inclass")
cutoff
accuracy <- map_dbl(cutoff, function(x){
y_hat <- ifelse(dat$type == x, "Male", "Female")
mean(y_hat == dat$sex)
})
glimpse(accuracy)
max(accuracy)
best_cutoff <- cutoff[which.max(accuracy)]
best_cutoff
y_hat <- ifelse(dat$type==best_cutoff, "Male", "Female")
#y_hat <- factor(y_hat)
mean(y_hat == dat$sex)
summary(y_hat)
# tabulate each combination of prediction and actual value
table(predicted = y_hat, actual = dat$sex)
dat %>%
mutate(y_hat = y_hat) %>%
group_by(sex) %>%
summarize(accuracy = mean(y_hat == sex))
prev <- mean(y == "Male")
#y_hat - predicted data
#dat$sex - actual data
length(y_hat)
length(dat$sex)
class(y_hat)
class(dat$sex)
y_hat <- factor(y_hat)
actual <- factor(dat$sex)
